{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About the data:** <br>\n",
    "The dataset contains 2 folders: yes and no which contains 253 Brain MRI Images. The folder yes contains 155 Brain MRI Images that are tumorous and the folder no contains 98 Brain MRI Images that are non-tumorous. You can find [here](https://www.kaggle.com/navoneel/brain-mri-images-for-brain-tumor-detection)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is a small dataset, I used data augmentation in order to create more images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we could solve the data imbalance issue (since 61% of the data belongs to the tumorous class) using data augmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Necessary Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "import cv2\n",
    "import imutils\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "import time    \n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return f\"{h}:{m}:{round(s,1)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(file_dir, n_generated_samples, save_to_dir):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        file_dir: A string representing the directory where images that we want to augment are found.\n",
    "        n_generated_samples: A string representing the number of generated samples using the given image.\n",
    "        save_to_dir: A string representing the directory in which the generated images will be saved.\n",
    "    \"\"\"\n",
    "    \n",
    "    #from keras.preprocessing.image import ImageDataGenerator\n",
    "    #from os import listdir\n",
    "    \n",
    "    data_gen = ImageDataGenerator(rotation_range=10, \n",
    "                                  width_shift_range=0.1, \n",
    "                                  height_shift_range=0.1, \n",
    "                                  shear_range=0.1, \n",
    "                                  brightness_range=(0.3, 1.0),\n",
    "                                  horizontal_flip=True, \n",
    "                                  vertical_flip=True, \n",
    "                                  fill_mode='nearest'\n",
    "                                 )\n",
    "\n",
    "    \n",
    "    for filename in listdir(file_dir):\n",
    "        # load the image\n",
    "        image = cv2.imread(file_dir + '\\\\' + filename)\n",
    "        # reshape the image\n",
    "        image = image.reshape((1,)+image.shape)\n",
    "        # prefix of the names for the generated sampels.\n",
    "        save_prefix = 'aug_' + filename[:-4]\n",
    "        # generate 'n_generated_samples' sample images\n",
    "        i=0\n",
    "        for batch in data_gen.flow(x=image, batch_size=1, save_to_dir=save_to_dir, \n",
    "                                           save_prefix=save_prefix, save_format='jpg'):\n",
    "            i += 1\n",
    "            if i > n_generated_samples:\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that 61% of the data (155 images) are tumorous. And, 39% of the data (98 images) are non-tumorous.<br>\n",
    "So, in order to balance the data we can generate 9 new images for every image that belongs to 'no' class and 6 images for every image that belongs the 'yes' class.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "\n",
    "# Define your base paths\n",
    "original_data_path = 'path/to/original/data/'  # Replace with your actual path\n",
    "augmented_data_path = '/home/ghost/Desktop/Brain-Tumor-Detection-master/augmented data'  # Changed space to underscore for better practice\n",
    "\n",
    "# Define the specific paths\n",
    "yes_path = os.path.join(original_data_path, '/home/ghost/Desktop/Brain-Tumor-Detection-master/augmented data/yes')  # Path to tumor images\n",
    "no_path = os.path.join(original_data_path, '/home/ghost/Desktop/Brain-Tumor-Detection-master/augmented data/no')    # Path to non-tumor images\n",
    "\n",
    "# Create the augmented directories if they don't exist\n",
    "os.makedirs(os.path.join(augmented_data_path, 'yes'), exist_ok=True)\n",
    "os.makedirs(os.path.join(augmented_data_path, 'no'), exist_ok=True)\n",
    "\n",
    "# Define your augmentation function\n",
    "def augment_data(file_dir, n_generated_samples, save_to_dir):\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    for filename in os.listdir(file_dir):\n",
    "        image = cv2.imread(os.path.join(file_dir, filename))\n",
    "        if image is None:\n",
    "            continue\n",
    "            \n",
    "        image = image.reshape((1,) + image.shape)\n",
    "        save_prefix = 'aug_' + os.path.splitext(filename)[0]\n",
    "        \n",
    "        i = 0\n",
    "        for batch in datagen.flow(image, batch_size=1, save_to_dir=save_to_dir,\n",
    "                                 save_prefix=save_prefix, save_format='jpg'):\n",
    "            i += 1\n",
    "            if i > n_generated_samples:\n",
    "                break\n",
    "\n",
    "# Now call the function with the defined paths\n",
    "augment_data(file_dir=yes_path, n_generated_samples=6, save_to_dir=os.path.join(augmented_data_path, 'yes'))\n",
    "augment_data(file_dir=no_path, n_generated_samples=9, save_to_dir=os.path.join(augmented_data_path, 'no'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many tumorous and non-tumorous examples after performing data augmentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_summary(main_path):\n",
    "    \n",
    "    yes_path = main_path+'yes'\n",
    "    no_path = main_path+'no'\n",
    "        \n",
    "    # number of files (images) that are in the the folder named 'yes' that represent tumorous (positive) examples\n",
    "    m_pos = len(listdir(yes_path))\n",
    "    # number of files (images) that are in the the folder named 'no' that represent non-tumorous (negative) examples\n",
    "    m_neg = len(listdir(no_path))\n",
    "    # number of all examples\n",
    "    m = (m_pos+m_neg)\n",
    "    \n",
    "    pos_prec = (m_pos* 100.0)/ m\n",
    "    neg_prec = (m_neg* 100.0)/ m\n",
    "    \n",
    "    print(f\"Number of examples: {m}\")\n",
    "    print(f\"Percentage of positive examples: {pos_prec}%, number of pos examples: {m_pos}\") \n",
    "    print(f\"Percentage of negative examples: {neg_prec}%, number of neg examples: {m_neg}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 19455\n",
      "Percentage of positive examples: 44.61%\n",
      "Percentage of negative examples: 55.39%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "\n",
    "# Define your base paths correctly\n",
    "main_path = '/home/ghost/Desktop/Brain-Tumor-Detection-master/augmented data/'  # Note the trailing slash\n",
    "yes_path = os.path.join(main_path, 'yes')  # Proper path joining\n",
    "no_path = os.path.join(main_path, 'no')    # Proper path joining\n",
    "\n",
    "def data_summary(main_path):\n",
    "    # Verify paths exist first\n",
    "    if not os.path.exists(yes_path):\n",
    "        raise FileNotFoundError(f\"Directory not found: {yes_path}\")\n",
    "    if not os.path.exists(no_path):\n",
    "        raise FileNotFoundError(f\"Directory not found: {no_path}\")\n",
    "    \n",
    "    # Count files\n",
    "    m_pos = len([f for f in os.listdir(yes_path) if os.path.isfile(os.path.join(yes_path, f))])\n",
    "    m_neg = len([f for f in os.listdir(no_path) if os.path.isfile(os.path.join(no_path, f))])\n",
    "    \n",
    "    # Number of all examples\n",
    "    m = (m_pos + m_neg)\n",
    "    \n",
    "    # Porportion\n",
    "    pos_prec = (m_pos*100.0)/m\n",
    "    neg_prec = (m_neg*100.0)/m\n",
    "    \n",
    "    print(f\"Number of examples: {m}\")\n",
    "    print(f\"Percentage of positive examples: {pos_prec:.2f}%\")\n",
    "    print(f\"Percentage of negative examples: {neg_prec:.2f}%\")\n",
    "\n",
    "# Call the function\n",
    "data_summary(main_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it for this notebook. Now, we can use the augmented data to train our convolutional neural network."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
